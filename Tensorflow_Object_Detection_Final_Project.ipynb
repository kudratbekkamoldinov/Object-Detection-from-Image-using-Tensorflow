{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "06k_uzcgaNan"
      },
      "cell_type": "markdown",
      "source": [
        "Installing packages to run Tensorflow-Object Detetion_API\n",
        "* install protobuf and cython\n",
        "* clone tensoflow models github\n",
        "* build protobuf\n",
        "* at the end test installation, so you must see pass 13 test in a short time\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "t0S8oRXk9rYd",
        "outputId": "914dc974-be7f-437e-d023-211e302f659d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "#!pip install jupyter\n",
        "#!pip install matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5.2).\n",
            "The following additional packages will be installed:\n",
            "  blt libimagequant0 libpython2-stdlib python-backports.functools-lru-cache\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-soupsieve python-webencodings python2\n",
            "  python2-minimal tk8.6-blt2.5\n",
            "Suggested packages:\n",
            "  blt-demo python-genshi python-lxml-dbg python-lxml-doc python-pil-doc\n",
            "  python-pil-dbg python-setuptools tix python-tk-dbg python2-doc\n",
            "The following NEW packages will be installed:\n",
            "  blt libimagequant0 libpython2-stdlib python-backports.functools-lru-cache\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-soupsieve python-tk\n",
            "  python-webencodings python2 python2-minimal tk8.6-blt2.5\n",
            "0 upgraded, 18 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 2,435 kB of archives.\n",
            "After this operation, 12.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 tk8.6-blt2.5 amd64 2.5.3+dfsg-4 [572 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 blt amd64 2.5.3+dfsg-4 [4,944 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libimagequant0 amd64 2.12.2-1.1 [31.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-backports.functools-lru-cache all 1.5-3build1 [6,520 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-soupsieve all 1.9.5+dfsg-1 [29.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-bs4 all 4.8.2-1 [83.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pkg-resources all 44.0.0-2ubuntu0.1 [130 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-chardet all 3.0.4-4build1 [80.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-six all 1.14.0-2 [12.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-webencodings all 0.5.1-1ubuntu1 [10.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-html5lib all 1.0.1-2 [84.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-lxml amd64 4.5.0-1ubuntu0.5 [950 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-olefile all 0.46-2 [33.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-pil amd64 6.2.1-3 [320 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-tk amd64 2.7.18-1 [25.3 kB]\n",
            "Fetched 2,435 kB in 1s (1,691 kB/s)\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 122541 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 122570 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package tk8.6-blt2.5.\n",
            "Preparing to unpack .../01-tk8.6-blt2.5_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package blt.\n",
            "Preparing to unpack .../02-blt_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking blt (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../03-libimagequant0_2.12.2-1.1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Selecting previously unselected package python-backports.functools-lru-cache.\n",
            "Preparing to unpack .../04-python-backports.functools-lru-cache_1.5-3build1_all.deb ...\n",
            "Unpacking python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Selecting previously unselected package python-soupsieve.\n",
            "Preparing to unpack .../05-python-soupsieve_1.9.5+dfsg-1_all.deb ...\n",
            "Unpacking python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Selecting previously unselected package python-bs4.\n",
            "Preparing to unpack .../06-python-bs4_4.8.2-1_all.deb ...\n",
            "Unpacking python-bs4 (4.8.2-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../07-python-pkg-resources_44.0.0-2ubuntu0.1_all.deb ...\n",
            "Unpacking python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../08-python-chardet_3.0.4-4build1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-4build1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.14.0-2_all.deb ...\n",
            "Unpacking python-six (1.14.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../10-python-webencodings_0.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../11-python-html5lib_1.0.1-2_all.deb ...\n",
            "Unpacking python-html5lib (1.0.1-2) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../12-python-lxml_4.5.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../13-python-olefile_0.46-2_all.deb ...\n",
            "Unpacking python-olefile (0.46-2) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../14-python-pil_6.2.1-3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (6.2.1-3) ...\n",
            "Selecting previously unselected package python-tk.\n",
            "Preparing to unpack .../15-python-tk_2.7.18-1_amd64.deb ...\n",
            "Unpacking python-tk (2.7.18-1) ...\n",
            "Setting up tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up blt (2.5.3+dfsg-4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up python-six (1.14.0-2) ...\n",
            "Setting up libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Setting up python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Setting up python-tk (2.7.18-1) ...\n",
            "Setting up python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Setting up python-olefile (0.46-2) ...\n",
            "Setting up python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Setting up python-html5lib (1.0.1-2) ...\n",
            "Setting up python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (6.2.1-3) ...\n",
            "Setting up python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Setting up python-chardet (3.0.4-4build1) ...\n",
            "Setting up python-bs4 (4.8.2-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (0.29.34)\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 85822, done.\u001b[K\n",
            "remote: Counting objects: 100% (1421/1421), done.\u001b[K\n",
            "remote: Compressing objects: 100% (615/615), done.\u001b[K\n",
            "remote: Total 85822 (delta 881), reused 1297 (delta 800), pack-reused 84401\u001b[K\n",
            "Receiving objects: 100% (85822/85822), 598.76 MiB | 34.96 MiB/s, done.\n",
            "Resolving deltas: 100% (61388/61388), done.\n",
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n",
            "2023-06-09 04:49:20.788958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-09 04:49:21.781137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_test.py\", line 20, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 37, in <module>\n",
            "    from object_detection.meta_architectures import deepmac_meta_arch\n",
            "  File \"/content/models/research/object_detection/meta_architectures/deepmac_meta_arch.py\", line 28, in <module>\n",
            "    import tensorflow_io as tfio  # pylint:disable=g-import-not-at-top\n",
            "ModuleNotFoundError: No module named 'tensorflow_io'\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iAvJ958NZS2H"
      },
      "cell_type": "markdown",
      "source": [
        "Imports\n",
        "removing check tf version , by default last version installed on colab\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CMrf7zaT-WYP",
        "outputId": "1b9736ad-77a2-4bcf-de34-8fa42e0a5a60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "print('tensorflow version = ',tf.__version__)\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version =  2.12.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MxaIKjzQbmbU"
      },
      "cell_type": "markdown",
      "source": [
        "* change directory to use utils"
      ]
    },
    {
      "metadata": {
        "id": "Tnls8IfmDBOa",
        "outputId": "b0f71735-cc23-4433-c567-835c886886c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "N5c42uNYD7hU",
        "outputId": "4bea32d4-c67f-4341-a0dd-bdf83e88d921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ./object_detection/\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6vzckSSVES_X"
      },
      "cell_type": "code",
      "source": [
        "# library to display the images\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-UrbS9_b55v"
      },
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-_G2G9IEWGy"
      },
      "cell_type": "code",
      "source": [
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7rLIh83cI8l"
      },
      "cell_type": "markdown",
      "source": [
        "* download model"
      ]
    },
    {
      "metadata": {
        "id": "oHzwS9h_Edbq"
      },
      "cell_type": "code",
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PJhW9eq6i04"
      },
      "cell_type": "markdown",
      "source": [
        "* load model from graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "hRkTXmfo2uHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b9438b-9b83-4445-eb9a-c632671bb231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VbWCa5BqEgjv"
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0BmzJZ7QfE"
      },
      "cell_type": "markdown",
      "source": [
        " define function that load image as np.array"
      ]
    },
    {
      "metadata": {
        "id": "v84EYXqhElns"
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQxx11OmFox7",
        "outputId": "420981de-7aed-4906-f951-7f627e8dfc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "print('/content/photo_2023-06-09_01-59-13.jpg')\n",
        "!ls ./test_images/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n",
            "/content/photo_2023-06-09_01-59-13.jpg\n",
            "ducky  image1.jpg  image2.jpg  image3.jpg  image_info.txt  snapshot_serengeti\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5NpO41TzBUSV"
      },
      "cell_type": "markdown",
      "source": [
        " read all jpg image in test_image folder"
      ]
    },
    {
      "metadata": {
        "id": "ahNqgt1BABrm"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "TEST_IMAGE_PATHS = []\n",
        "for filename in glob.iglob('/content/new-york-city-traffic-wallpaper-thumb.jpg', recursive=True):\n",
        "    TEST_IMAGE_PATHS.append(filename)\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDaadPuQBTti"
      },
      "cell_type": "markdown",
      "source": [
        "this code just read pictures that have 'image' at the first of their name so i comment it & and use above code!"
      ]
    },
    {
      "metadata": {
        "id": "DDcZR-zGEsE9"
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIIqgI9AmqEM"
      },
      "cell_type": "markdown",
      "source": [
        "A for loop that read all images in test_images path and feed into the network then show results"
      ]
    },
    {
      "metadata": {
        "id": "HwlzZer9Eunc"
      },
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "# Rest of your code\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=4)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "    plt.grid(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}